import streamlit as st
from fastai.vision.all import load_learner
from components.VoCoderRecognition.lib.melspectrogram_custom import generate_single_spec
import os
from PIL import Image
from context.userContext import getUserContext
import pandas as pd

def uploaded_model_button():
    new_model = st.file_uploader("Upload a PKL file containing the model", type=["pkl"])
    if new_model:
        global model
        try:
            model = load_learner(new_model)
            show_model_eval = st.checkbox("üîç Show Model Evaluation")
            if show_model_eval:
                st.write(model.eval())

        except Exception as e:
            st.error(f"Error loading model: {e}")

getUserContext()
model = None
SAVE_DIR = f".tmp/{st.session_state.username}/uploads"
os.makedirs(SAVE_DIR, exist_ok=True)


if "trained_model" in st.session_state: # this case, it detected that the user just trained a model
    st.success("It was detected a Model just trained successfully!")

    option = st.radio("Choose an option:", ["Use trained model", "Upload a new model"])

    if option == "Use trained model":
        try:
            model = load_learner(st.session_state.trained_model)
        except Exception as e:
            st.error(f"An unexpected error occurred while loading the model: {e}")

    if option == "Upload a new model":
        uploaded_model_button()
        # Load a model
        
else:
    st.warning("It was not detected a Model just trained yet! But you can try upload your own to to test an audio.")
    uploaded_model_button()


if model is not None:
    # Upload an audio file to test the model
    uploaded_audio = st.file_uploader("Upload an audio to test", type=["wav"])

    if uploaded_audio:
        st.write(f"Audio uploaded: {uploaded_audio.name}")

        save_path = os.path.join(SAVE_DIR, uploaded_audio.name)

        with open(save_path, "wb") as f:
            f.write(uploaded_audio.read())

        st.audio(save_path, format="audio/wav")

        generate_single_spec(
                            "mel",
                            SAVE_DIR,
                            SAVE_DIR,
                            uploaded_audio.name,
                            0,
                            crop_width=64,
                            discard_if_too_narrow=True
                        )
        spec_name = os.path.splitext(uploaded_audio.name)[0]+".png"
        spec_save_path= os.path.join(SAVE_DIR, spec_name)


        st.markdown("---")
        st.subheader("Analysis Visualization:")
        st.write(
            "Before classification by the CNN model, the audio transforms into a **Mel-frequency spectrogram**. "
            "This visual representation captures the audio's frequency and temporal characteristics, serving as the **foundation for the model's analysis**. "
            "The spectrogram generated from your audio is displayed below:"
        )
        st.image(
            spec_save_path,
            use_container_width=False,
            caption=f"Mel Spectrogram of the audio: {os.path.splitext(uploaded_audio.name)[0]}"
        )
        
        ######################################
        st.markdown("---")
        st.subheader("Analysis Results:")

        test_image = Image.open(spec_save_path)
        test_image = test_image.resize((128, 128))
        test_image = test_image.convert("RGB")

        pred, pred_idx, probs = model.predict(test_image)
        class_labels = model.dls.vocab


        predicted_class_name = class_labels[pred_idx.item()]
        
        if predicted_class_name == "bonafide": # Checar se √© humano
            st.success("### ‚úÖ This audio is classified as **HUMAN**!")
            st.write("Based on our AI model's analysis, this audio exhibits characteristics consistent with un-synthesized human speech.")
        else: # Checar se √© sintetizado
            st.error("### ‚ùå This audio is classified as **MACHINE-GENERATED**!")
            st.write(f"According to the model's analysis, this audio possesses patterns characteristic of synthesized speech. The most probable class is: **{predicted_class_name}**.")
            
            st.info(f"**Note:** The model was trained to identify audio generated by specific vocoders. While the result points to \
                      '{predicted_class_name}', it's possible the audio was generated by a similar vocoder \
                      whose characteristics resemble those learned for this class. The AI makes its best estimate based on the training data.")

        st.markdown("---")
        st.subheader("Metrics:")

        st.metric(label="üîç **Most Probable Prediction**", value=f"Class {pred_idx.item()}: {predicted_class_name}")
        st.metric(label="üìä **Probability of Main Prediction**", value=f"{probs[pred_idx.item()]:.2%}")

        with st.expander("### üìà Full Probability Distribution:"):
            df = pd.DataFrame({
                "Class": [label for label in class_labels],
                "Probability": probs
            })
            st.dataframe(df.style.format({"Probability": "{:.2%}"}), hide_index=True)
            st.bar_chart(df.set_index("Class"))
